{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id  data\n",
      "0        0        0   1.0\n",
      "1        0        2   1.0\n",
      "2        0      120   1.0\n",
      "3        0      128   1.0\n",
      "4        0      211   1.0\n",
      "5        0      232   1.0\n",
      "6        0      282   1.0\n",
      "7        0      453   1.0\n",
      "8        0      458   1.0\n",
      "9        0      491   1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_train_path = \"Dataset/data_train.csv\"\n",
    "\n",
    "URM_all_dataframe = pd.read_csv(data_train_path)\n",
    "print(URM_all_dataframe.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 141 (0.39 %) of 35736 users have no sampled items\n",
      "EvaluatorHoldout: Ignoring 141 ( 0.4%) Users that have less than 1 test interactions\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "\n",
    "\n",
    "\n",
    "URM_all = sps.coo_matrix((URM_all_dataframe['data'], (URM_all_dataframe['user_id'], URM_all_dataframe['item_id'])))\n",
    "URM_all = URM_all.tocsr()\n",
    "\n",
    "URM_train_validation, URM_test = split_train_in_two_percentage_global_sample(URM_all, train_percentage = 0.8)\n",
    "evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Recommenders.SLIM.SLIMElasticNetRecommender_Peppe import MultiThreadSLIM_SLIMElasticNetRecommender\n",
    "from Recommenders.EASE_R.EASE_R_Recommender import EASE_R_Recommender\n",
    "\n",
    "recommender_slimNet = MultiThreadSLIM_SLIMElasticNetRecommender(URM_train_validation)\n",
    "recommender_slimNet.fit(topK=142, alpha = 9.521340863590419e-05, l1_ratio = 0.4033590645217344)\n",
    "\n",
    "recommender_easeR = EASE_R_Recommender(URM_train_validation)\n",
    "recommender_easeR.fit(l2_norm=33.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Recommenders.KNN.ItemKNNCustomSimilarityRecommender import ItemKNNCustomSimilarityRecommender\n",
    "\n",
    "def objective_function(trial):\n",
    "\n",
    "    alpha = trial.suggest_uniform('alpha', 0.0, 1.0)\n",
    "\n",
    "\n",
    "    recommender = ItemKNNCustomSimilarityRecommender(URM_train_validation)\n",
    "\n",
    "    new_similarity = recommender_slimNet.W_sparse * alpha + recommender_rp3.W_sparse * (1-alpha)\n",
    "\n",
    "    recommender.fit(new_similarity)\n",
    "\n",
    "    result_dict, _ = evaluator_test.evaluateRecommender(recommender)\n",
    "\n",
    "    MAP = result_dict.loc[10][\"MAP\"]\n",
    "    \n",
    "    return MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveResults(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results_df = pd.DataFrame(columns = [\"result\"])\n",
    "    \n",
    "    def __call__(self, optuna_study, optuna_trial):\n",
    "        hyperparam_dict = optuna_trial.params.copy()\n",
    "        hyperparam_dict[\"result\"] = optuna_trial.values[0]\n",
    "        \n",
    "        self.results_df = pd.concat([self.results_df, pd.DataFrame([hyperparam_dict])], ignore_index=True)\n",
    "        self.results_df.to_csv(\"logs/Hybrid/hybrid_slim_EASER_MM.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "optuna_study = optuna.create_study(study_name=\"hybrid_slim_ep3\", direction=\"maximize\")\n",
    "        \n",
    "save_results = SaveResults()\n",
    "        \n",
    "optuna_study.optimize(objective_function,\n",
    "                      callbacks=[save_results],\n",
    "                      n_trials = 100\n",
    "                      )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
